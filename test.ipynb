{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_file = \"happy_data.txt\"\n",
    "data = np.loadtxt(data_file)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = data[:, :-1]  # Features are all columns except the last one\n",
    "y = data[:, -1]   # Labels are the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152, 234), (152,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00253e-01, 2.36387e-01, 2.38085e-01, 1.42594e-01, 2.07135e-01,\n",
       "       1.91964e-01, 2.03766e-01, 1.90994e-01, 1.55303e-01, 2.78311e-01,\n",
       "       1.94608e-01, 1.23592e-01, 3.59929e-01, 2.03269e-01, 1.09588e-01,\n",
       "       5.03824e-01, 1.99935e-01, 1.16338e-01, 5.85421e-01, 1.89364e-01,\n",
       "       1.37107e-01, 6.58261e-01, 1.84483e-01, 1.75407e-01, 1.73800e-01,\n",
       "       3.13072e-01, 2.39428e-01, 2.11762e-01, 2.93417e-01, 2.00836e-01,\n",
       "       2.69277e-01, 2.87443e-01, 1.93054e-01, 3.32242e-01, 3.17151e-01,\n",
       "       2.15436e-01, 2.74098e-01, 3.26582e-01, 2.00783e-01, 2.16525e-01,\n",
       "       3.27503e-01, 2.08576e-01, 5.25265e-01, 3.17401e-01, 2.26300e-01,\n",
       "       6.44450e-01, 2.89865e-01, 2.21401e-01, 5.87104e-01, 2.86625e-01,\n",
       "       2.08602e-01, 6.82016e-01, 3.06626e-01, 2.63565e-01, 6.40959e-01,\n",
       "       3.21542e-01, 2.28855e-01, 5.83706e-01, 3.24148e-01, 2.16102e-01,\n",
       "       2.52667e-01, 6.49032e-01, 2.24084e-01, 2.83556e-01, 6.77140e-01,\n",
       "       2.13055e-01, 3.09389e-01, 6.95087e-01, 1.91888e-01, 3.45009e-01,\n",
       "       7.10778e-01, 1.72576e-01, 3.87399e-01, 7.20788e-01, 1.57753e-01,\n",
       "       4.38397e-01, 7.23927e-01, 1.53380e-01, 4.88449e-01, 7.18728e-01,\n",
       "       1.61367e-01, 5.28924e-01, 7.07265e-01, 1.79201e-01, 5.59885e-01,\n",
       "       6.32569e-01, 1.84741e-01, 5.88951e-01, 6.35915e-01, 2.13844e-01,\n",
       "       6.12317e-01, 6.41666e-01, 2.36684e-01, 5.84674e-01, 6.71623e-01,\n",
       "       2.23951e-01, 4.39316e-01, 5.16519e-01, 0.00000e+00, 4.36975e-01,\n",
       "       5.49716e-01, 9.36620e-02, 3.25860e-01, 5.36011e-01, 1.36846e-01,\n",
       "       5.43290e-01, 5.32484e-01, 1.44139e-01, 4.37847e-01, 5.43051e-01,\n",
       "       6.69180e-02, 5.60665e-01, 4.95680e-01, 1.28962e-01, 2.52667e-01,\n",
       "       6.49032e-01, 2.24084e-01, 3.84626e-01, 6.33393e-01, 1.37189e-01,\n",
       "       4.35039e-01, 6.34535e-01, 1.33033e-01, 4.84670e-01, 6.31726e-01,\n",
       "       1.40771e-01, 4.30104e-01, 0.00000e+00, 1.40494e-01, 5.39681e-01,\n",
       "       2.98200e-03, 1.55323e-01, 6.30274e-01, 2.08800e-02, 1.98876e-01,\n",
       "       7.12459e-01, 5.80600e-02, 2.70018e-01, 7.64981e-01, 1.11645e-01,\n",
       "       3.48798e-01, 7.98094e-01, 1.77646e-01, 4.23513e-01, 8.17952e-01,\n",
       "       2.47660e-01, 5.02337e-01, 8.29732e-01, 3.34233e-01, 5.64879e-01,\n",
       "       8.31609e-01, 4.15895e-01, 5.94130e-01, 8.31589e-01, 4.98927e-01,\n",
       "       5.98257e-01, 8.23300e-01, 5.87584e-01, 5.84027e-01, 8.00322e-01,\n",
       "       6.79355e-01, 5.50572e-01, 7.62502e-01, 7.49377e-01, 4.91178e-01,\n",
       "       7.16708e-01, 7.96698e-01, 4.28016e-01, 6.58563e-01, 8.38560e-01,\n",
       "       3.76315e-01, 6.11773e-01, 8.68642e-01, 3.33351e-01, 5.65062e-01,\n",
       "       8.95941e-01, 2.87172e-01, 5.11137e-01, 9.16682e-01, 2.54439e-01,\n",
       "       4.42039e-01, 9.25839e-01, 2.40407e-01, 3.71454e-01, 9.20630e-01,\n",
       "       2.47427e-01, 3.14617e-01, 9.03227e-01, 2.74503e-01, 2.63524e-01,\n",
       "       8.78286e-01, 3.16096e-01, 2.12629e-01, 8.49795e-01, 3.54719e-01,\n",
       "       1.48248e-01, 8.09264e-01, 4.01173e-01, 9.47570e-02, 7.63175e-01,\n",
       "       4.58981e-01, 4.78180e-02, 6.94612e-01, 5.14608e-01, 1.69870e-02,\n",
       "       6.03903e-01, 5.45491e-01, 3.30200e-03, 5.15258e-01, 5.58636e-01,\n",
       "       0.00000e+00, 4.31488e-01, 5.53998e-01, 8.40000e-05, 3.48449e-01,\n",
       "       5.24634e-01, 1.22110e-02, 2.60193e-01, 4.62533e-01, 3.48780e-02,\n",
       "       1.88350e-01, 3.85826e-01, 7.40010e-02, 1.20150e-01, 3.15060e-01,\n",
       "       1.34046e-01, 6.44840e-02, 2.42711e-01, 2.23042e-01, 2.50330e-02,\n",
       "       1.80306e-01, 3.18049e-01, 5.30000e-03, 1.46133e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0., 1., 0., 2., 2., 1., 3., 1., 0., 0., 0., 3., 2., 1., 1.,\n",
       "       2., 1., 2., 0., 0., 1., 1., 3., 0., 0., 3., 2., 1., 2., 2., 2., 1.,\n",
       "       1., 0., 1., 0., 0., 2., 1., 1., 1., 2., 3., 1., 2., 3., 0., 2., 2.,\n",
       "       0., 2., 1., 1., 1., 3., 2., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 2., 0., 3., 3., 0., 0., 3., 0., 2., 2., 3., 0., 2., 1.,\n",
       "       3., 0., 2., 1., 1., 3., 0., 0., 1., 2., 1., 3., 2., 3., 0., 2., 2.,\n",
       "       2., 1., 1., 2., 0., 0., 2., 3., 3., 1., 0., 1., 1., 2., 3., 1., 3.,\n",
       "       2., 2., 1., 1., 1., 0., 0., 3., 0., 0., 2., 2., 1., 3., 1., 0., 3.,\n",
       "       2., 0., 2., 2., 2., 3., 1., 2., 2., 1., 1., 3., 0., 0., 1., 2., 0.,\n",
       "       0., 2., 2., 1., 3., 0., 3., 1., 1., 1., 2., 1., 0., 1., 3., 3., 2.,\n",
       "       1., 2., 1., 0., 2., 1., 0., 3., 2., 1., 3., 1., 1., 0., 3., 1., 1.,\n",
       "       0., 2., 1., 1., 2., 1., 1., 3., 3., 2., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       3., 3., 1., 0., 1., 0., 1., 1., 0., 1., 1., 3., 0., 3., 0., 3., 1.,\n",
       "       0., 1., 0., 1., 0., 3., 3., 0., 3., 2., 3., 0., 1., 3., 0., 2., 2.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 2., 2., 1., 3., 0., 2., 3., 3., 3., 1.,\n",
       "       2., 1., 1., 0., 2., 3., 1., 0., 1., 1., 0., 3., 1., 0., 2., 1., 1.,\n",
       "       0., 0., 1., 3., 0., 3., 0., 2., 2., 3., 2., 0., 1., 0., 0., 3., 0.,\n",
       "       0., 1., 0., 2., 3., 0., 2., 3., 0., 1., 3., 1., 0., 3., 2., 2., 0.,\n",
       "       3., 2., 2., 1., 2., 0., 2., 3., 1., 0., 0., 2., 1., 0., 0., 1., 2.,\n",
       "       3., 1., 2., 1., 2., 0., 1., 1., 3., 0., 3., 0., 2., 0., 1., 0., 2.,\n",
       "       3., 0., 1., 0., 2., 0., 1., 2., 3., 2., 0., 0., 3., 1., 1., 1., 2.,\n",
       "       3., 0., 1., 0., 1., 2., 1., 2., 1., 1., 1., 2., 1., 2., 2., 0., 1.,\n",
       "       2., 2., 2., 2., 3., 1., 2., 2., 0., 1., 1., 0., 2., 0., 2., 0., 1.,\n",
       "       2., 1., 0., 0., 3., 1., 2., 2., 2., 1., 1., 3., 2., 1., 0., 3., 0.,\n",
       "       2., 3., 2., 0., 0., 2., 0., 1., 3., 2., 1., 1., 2., 2., 0., 1., 0.,\n",
       "       1., 0., 0., 2., 0., 0., 1., 2., 2., 1., 3., 0., 2., 0., 1., 2., 2.,\n",
       "       3., 3., 3., 0., 0., 2., 2., 0., 1., 0., 2., 1., 0., 0., 1., 2., 1.,\n",
       "       0., 2., 3., 1., 1., 2., 3., 2., 2., 2., 3., 0., 0., 0., 2., 1., 0.,\n",
       "       2., 3., 0., 2., 0., 3., 1., 0., 3., 2., 2., 0., 2., 1., 1., 0., 2.,\n",
       "       2., 3., 2., 1., 0., 0., 3.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (502, 234)\n",
      "y shape: (502,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Đọc từng file txt đã lưu và gán nhãn mới theo đúng thư mục cảm xúc\n",
    "def load_and_label_data(file_path, new_label):\n",
    "    data = np.loadtxt(file_path)\n",
    "    data[:, -1] = new_label  # Thay đổi nhãn của cột cuối cùng\n",
    "    return data\n",
    "\n",
    "# Đường dẫn đến các file txt tương ứng với từng cảm xúc\n",
    "files_with_labels = {\n",
    "    'anger_data.txt': 0,    # anger = 0\n",
    "    'happy_data.txt': 1,    # happy = 1\n",
    "    'neutral_data.txt': 2,  # neutral = 2\n",
    "    'sadness_data.txt': 3   # sadness = 3\n",
    "}\n",
    "\n",
    "# Tạo danh sách để chứa dữ liệu tổng hợp\n",
    "combined_data = []\n",
    "\n",
    "# Đọc và ghép dữ liệu từ từng file, thay nhãn theo cảm xúc\n",
    "for file, label in files_with_labels.items():\n",
    "    data = load_and_label_data(file, label)\n",
    "    combined_data.append(data)\n",
    "\n",
    "# Chuyển tất cả dữ liệu thành một mảng lớn\n",
    "combined_data = np.vstack(combined_data)\n",
    "\n",
    "# Trộn ngẫu nhiên dữ liệu để không bị theo thứ tự cảm xúc\n",
    "np.random.shuffle(combined_data)\n",
    "\n",
    "# Lưu dữ liệu đã trộn vào file cuối cùng\n",
    "np.savetxt('data_12.txt', combined_data)\n",
    "\n",
    "# Tách X (features) và y (labels)\n",
    "X = combined_data[:, :-1]  # Features là tất cả các cột trừ cột cuối cùng\n",
    "y = combined_data[:, -1]   # Labels là cột cuối cùng\n",
    "\n",
    "# In ra kích thước của X và y để kiểm tra\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Bây giờ bạn có thể sử dụng X và y để huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "input = scaler.transform(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from utils import get_face_landmarks, IMPORTANT_LANDMARKS\n",
    "\n",
    "# Load mô hình phân loại cảm xúc\n",
    "model = load_model('model_data_12.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B7B4B6660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "emotion_prediction = model.predict(input)\n",
    "predicted_emotion = np.argmax(emotion_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viet Hung\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng điểm landmarks: 78\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from utils import get_face_landmarks, IMPORTANT_LANDMARKS\n",
    "\n",
    "# Đặt tên file kết quả tương ứng với cảm xúc (ví dụ: 'neutral_data.txt')\n",
    "output_file = 'neutral_data.txt'\n",
    "\n",
    "output = []\n",
    "\n",
    "# Đọc ảnh đầu vào\n",
    "image_path = 'happy.png'  # Thay bằng đường dẫn ảnh của bạn\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Khởi tạo Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5\n",
    ") as face_mesh:\n",
    "\n",
    "    # Lấy landmarks từ ảnh\n",
    "    face_landmarks = get_face_landmarks(image, face_mesh)\n",
    "\n",
    "    # Kiểm tra xem landmarks có hợp lệ không\n",
    "    expected_landmark_length = len(IMPORTANT_LANDMARKS) * 3\n",
    "    if face_landmarks and len(face_landmarks) == expected_landmark_length:\n",
    "        # Gán nhãn cho cảm xúc hiện tại (ví dụ: 0 cho neutral)\n",
    "        emotion_index = 0  # Thay đổi nhãn phù hợp với cảm xúc\n",
    "        face_landmarks.append(emotion_index)  # Thêm label vào cuối landmarks\n",
    "        output.append(face_landmarks)\n",
    "\n",
    "        # Vẽ các điểm landmarks lên ảnh\n",
    "        for i in range(0, len(face_landmarks) - 1, 3):\n",
    "            x = int(face_landmarks[i])\n",
    "            y = int(face_landmarks[i + 1])\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)  # Vẽ điểm xanh lá tại mỗi landmark\n",
    "\n",
    "        print(f\"Số lượng điểm landmarks: {len(face_landmarks) // 3}\")  # In ra số lượng điểm\n",
    "    else:\n",
    "        print(f\"Lỗi khi xử lý ảnh: {image_path}\")\n",
    "\n",
    "# Hiển thị ảnh đầu ra với các landmarks\n",
    "cv2.imshow('Output Image with Landmarks', image)\n",
    "cv2.waitKey(0)  # Dừng lại cho đến khi bấm phím bất kỳ\n",
    "cv2.destroyAllWindows()  # Đóng tất cả cửa sổ hiển thị\n",
    "\n",
    "# Sau khi hoàn thành, lưu dữ liệu vào file txt tương ứng với cảm xúc\n",
    "np.savetxt(output_file, np.asarray(output), fmt='%f')\n",
    "\n",
    "print(f\"Lưu dữ liệu của cảm xúc vào {output_file} thành công!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
